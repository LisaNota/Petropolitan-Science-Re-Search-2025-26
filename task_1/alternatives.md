## Варианты ускорения алгоритма с помощью распараллеливания операциq/вероятнстных алгоритмов


## 1) Распараллеливание (точный результат)

### 1.1. Конвейерная обработка (pipeline)
Файл обрабатывается потоком: **чтение → парсинг IPv6 → сортировка чанков → запись run-файлов**.  
Можно вынести чтение в отдельный поток/процесс, а парсинг и сортировку выполнять параллельно на нескольких воркерах. Это уменьшает простои CPU и диска: пока один процесс сортирует, другой уже читает и готовит следующий чанк.

### 1.2. Мультипроцессинг на этапе генерации runs
Самая тяжёлая CPU-часть — сортировка чанков. Её можно распараллелить через `multiprocessing`: главный процесс нарезает вход на чанки строк и отправляет их воркерам, воркеры парсят адреса в 16-байтный вид, сортируют и сохраняют независимые run-файлы.  
**Ограничение:** выгодно в основном на SSD/NVMe; на медленном HDD параллельная запись может упереться в диск.

### 1.3. Параллельное слияние runs (дерево слияний)
Если run-файлов очень много, их можно сливать параллельно: несколько процессов сливают группы runs в крупные промежуточные файлы, затем следующий уровень слияния и т.д.  
На практике ускорение появляется только при быстром диске и большом количестве runs; часто финальное слияние становится I/O-ограниченным, и параллельность даёт небольшой эффект.

## 2) Вероятностные алгоритмы

Если в задаче допустим **приближённый** ответ, можно отказаться от внешней сортировки и получить оценку за один проход по файлу с малой памятью.

### 2.1. HyperLogLog (HLL)
Поддерживает оценку мощности множества (числа уникальных элементов) по хешам входных значений.  
Один проход, память — от килобайт до сотен килобайт, высокая скорость, но результат приближённый; типичная относительная ошибка ≈ `1.04/√m`, где `m` — число регистров (например, при `m=16384` ошибка порядка ~0.8%).

### 2.2. KMV / MinHash (k минимальных хешей)
Хранится `k` минимальных значений хеша и по ним оценивается число уникальных. Эта вариация проще, чем HLL, тоже один проход и малая память `O(k)`, но снова приближённый результат; точность растёт как `~1/√k`.

## 3) Прочие оптимизации 

### 3.1. Настройка параметров внешней сортировки
- Увеличение размера чанка (`chunk_records`) уменьшает число run-файлов → снижает стоимость многоступенчатого merge.
- Увеличение `fan_in` (сколько runs сливается за раз) уменьшает число уровней слияния → меньше полных проходов по данным.

**Ограничения:** `chunk_records` упирается в RAM, `fan_in` — в лимит открытых файлов ОС.

### 3.2. Оптимизация ввода-вывода (I/O)
- Использование **бинарного формата** (16 байт на адрес) вместо строк уменьшает объём данных и ускоряет сортировку/слияние.
- Большие буферы чтения/записи (MB-уровень) снижают число системных вызовов и ускоряют работу на диске.

### 3.3. Бакетизация (partitioning) перед сортировкой
Можно сделать первый проход и разложить адреса по нескольким “бакетам” (например, по первому байту/хеш-префиксу), а затем считать уникальные внутри каждого бакета отдельно (внешней сортировкой).  
**Плюсы:** меньше размер каждой подзадачи, проще распараллелить по бакетам, уменьшается сложность финального merge.  
**Минусы:** дополнительный этап записи/чтения и потенциально много файлов (нужно разумно выбирать число бакетов).

## Итог
Для **точного** результата основные ускорения — мультипроцессинг на сортировке чанков, уменьшение числа run-файлов (большие чанки) и снижение уровней merge (больший `fan_in`), плюс оптимизация I/O.  
Для **приближённого** результата наиболее эффективный путь — **HyperLogLog**: один проход, очень малая память и контролируемая погрешность.

